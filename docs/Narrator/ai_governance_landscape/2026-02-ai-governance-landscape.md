---
layout: default
title: "2026-02"
parent: AI Governance Landscape
nav_order: 1
---

# AI Governance Landscape — 2026-02

> 本期追蹤 30 項 AI 治理動態，涵蓋 NIST 框架、NIST 洞察、歐盟法規，以及 CSA 雲端安全、ISO 標準與 SANS 威脅情報等延伸來源。

## 免責聲明

本報告由 AI 系統自動產出，基於公開資料源萃取與結構化分析。
內容僅供參考，不構成法律或合規建議。所有資訊應以原始發布機構
的正式文件為準。標註「[系統推論]」之內容為系統推論，尚未經人工驗證。

---

## 本月重點

1. **歐盟 AI Act 勘誤發布** — EU 於 2026-01-13 發布 Regulation (EU) 2024/1689 勘誤，明確排除線上空間適用範圍，修正原條文錯誤描述。（來源：EU，rule_type: amendment，enforcement: mandatory，binding_force: directly_applicable）

2. **歐盟 AI Gigafactories 建立框架** — Council Regulation (EU) 2026/150 修正 EuroHPC Joint Undertaking，擴展至 AI gigafactories 與量子運算基礎設施，新增會員國 17% 資本支出共同出資要求，聯盟出資增至 41.2 億歐元。（來源：EU，rule_type: amendment，enforcement: mandatory）

3. **Agentic AI 治理框架湧現** — CSA 發布多項 Agentic AI 治理指引，包括「Agentic Trust Framework」建立 AI 代理專用 Zero Trust 架構，以及「Levels of Autonomy」分級治理框架，標誌 AI 自主系統治理進入實務階段。（來源：CSA，rule_type: guidance，enforcement: recommended）

4. **ISO 發布 AI 透明度分類標準** — ISO/IEC 於 2025-11-11 發布 AI 系統透明度分類法（Transparency taxonomy of AI systems），為 AI 系統透明度評估提供國際標準化框架。（來源：ISO，rule_type: new，enforcement: recommended）

5. **NIST AI 資安整合進程持續** — NIST NCCoE 持續推動 Cyber AI Profile 系列工作坊，涵蓋 AI 系統元件安全、AI 驅動資安防禦、對抗 AI 攻擊等主題，並新設製造業與關鍵基礎設施 AI 經濟安全中心。（來源：NIST，rule_type: guidance/new，enforcement: informational/recommended）

---

## 區域動態比較

### 美國（NIST）

**NIST Frameworks（6 項）**：

| 文件 | 發布日期 | 狀態 | 重點 |
|------|----------|------|------|
| NIST Launches Centers for AI in Manufacturing and Critical Infrastructure | 2025-12-22 | final | 新設兩個 AI 經濟安全中心，負責製造業生產力提升與關鍵基礎設施防護，與 MITRE 合作開發 AI 代理工具 |
| Draft NIST Guidelines Rethink Cybersecurity for the AI Era | 2025-12-16 | draft | 重新思考 AI 時代的資安指引 |
| NCCoE Cyber AI Profile: Thwarting AI-enabled Cyber Attacks | 2025-09-02 | final | 對抗 AI 驅動網路攻擊的實務指引 |
| NCCoE Cyber AI Profile: Conducting AI-enabled Cyber Defense | 2025-08-19 | final | AI 驅動資安防禦工作坊 |
| NCCoE Cyber AI Profile: Securing AI System Components | 2025-08-05 | final | AI 系統元件安全工作坊 |
| Lessons Learned: Tool Use in Agent Systems | 2025-08-05 | final | AI 代理工具使用標準化分類法，改善供應鏈溝通、風險評估與事件報告 |

**NIST Cybersecurity Insights（4 項）**：

| 文件 | 發布日期 | 重點 |
|------|----------|------|
| IoT Product Manufacturers Foundational Activities Update | 2025-09-30 | IoT 產品製造商資安風險更新 |
| Impact of AI on the Cybersecurity Workforce | 2025-06-12 | AI 對資安人才的影響 |
| Cybersecurity and AI: Integrating Existing NIST Guidelines | 2025-05-22 | 整合現有 NIST 指引與 AI |
| Managing Cybersecurity and Privacy Risks in the Age of AI | 2024-09-19 | NIST AI 資安隱私風險管理專案啟動 |

### 美國（CSA Cloud Security Alliance）

本期 CSA 發布 13 項 AI 安全治理指引，成為最活躍的指引來源：

| 文件 | 日期 | Category | 重點 |
|------|------|----------|------|
| Time-to-Trust Survey | 2026-02-03 | identity | IAM 架構需擴展以容納 AI 代理 |
| Agentic Trust Framework (ATF) | 2026-01-29 | ai_security | 首個 AI 代理零信任治理規範 |
| Non-Human Identity Governance | 2026-01-27 | identity | 傳統 IGA 系統不足以治理非人類身分 |
| Great Divide: AI Splitting Cybersecurity | 2026-01-27 | ai_security | 2026 為 AI 資安應用分水嶺 |
| Leveling Up Autonomy in Agentic AI | 2026-01-26 | ai_security | AI 自主性層級分類與治理 |
| What if AI Knew When to Say 'I Don't Know'? | 2026-01-21 | ai_security | AI 不確定性校準與內在感知 |
| AI Governance Framework Adoption | 2026-01-13 | ai_security | 雲原生 AI 治理分階段採用方法 |
| From Security to Proof of AI Trust | 2026-01-13 | ai_security | AI 信任證明機制設計 |
| Global Privacy Trends 2026 | 2026-01-13 | compliance | 全球隱私合規進入新階段 |
| SaaS and AI Security in 2026 | 2026-01-13 | best_practices | AI 採用循 SaaS 進入模式 |
| Top 10 Predictions for Agentic AI | 2026-01-12 | ai_security | 2026 年 Agentic AI 趨勢預測 |
| First Question Security Should Ask | 2026-01-09 | best_practices | 安全團隊需以「Why」問題引導 AI 專案 |
| What AI Risks Are Hiding in Your Apps? | 2026-01-06 | ai_security | 應用程式嵌入式 AI 風險識別 |

### 歐盟

| 法規 | 發布日期 | 類型 | binding_force | 重點 |
|------|----------|------|---------------|------|
| Corrigendum to AI Act (EU) 2024/1689 | 2026-01-13 | amendment | directly_applicable | 修正線上空間適用範圍錯誤描述，明確排除線上空間 |
| Council Regulation (EU) 2026/150 (EuroHPC AI Gigafactories) | 2026-01-23 | amendment | directly_applicable | 擴展 EuroHPC 至 AI gigafactories，41.2 億歐元投資 |
| Council Regulation (EU) 2026/150 on EuroHPC Joint Undertaking | 2026-01-19 | amendment | directly_applicable | 建立會員國 17% 資本支出共同出資框架 |
| Corrigendum to (EU) 2024/1732 on EuroHPC AI Initiative | 2026-01-27 | amendment | informational | 術語更正：「AI factory」改為「AI facility」，無實質變動 |

**EU AI Act 適用範圍修正**：此次勘誤具實質影響，原文誤將線上空間納入適用範圍，修正後明確「線上空間不在適用範圍內，因其並非實體空間」。AI 系統提供者與部署者需重新評估線上環境的合規義務。

**EuroHPC AI Gigafactories 擴展**：新增職責包括：建立與營運 AI gigafactories、授予合格國家基礎設施「EuroHPC AI and Compute Infrastructure Seal」、管理會員國 RRF 貢獻與存取時間分配、建立 AI 處理器採購框架合約。此擴展強化歐盟在 AI 領域的技術主權與戰略自主性。

### 國際標準（ISO）

| 文件 | 發布日期 | 類型 | 重點 |
|------|----------|------|------|
| Information technology — AI — Transparency taxonomy of AI systems | 2025-11-11 | new | AI 系統透明度分類法國際標準 |

### 威脅情報（SANS ISC）

| 文件 | 發布日期 | 類型 | 重點 |
|------|----------|------|------|
| Detecting and Monitoring OpenClaw (clawdbot, moltbot) | 2026-02-03 | guidance | 新型 AI 代理框架 OpenClaw 需建立偵測監控機制 |
| Scanning for exposed Anthropic Models | 2026-02-02 | guidance | 偵測針對 Anthropic API 端點掃描活動 |

---

## 責任變動追蹤

| 來源 | 文件 | affected_roles | shift_type | shift_summary |
|------|------|---------------|------------|---------------|
| EU | AI Act Corrigendum | AI system providers, deployers, online platform operators | clarified | 明確排除線上空間適用範圍，修正原條文錯誤描述 |
| EU | Council Regulation 2026/150 | EuroHPC JU, Member States, AI gigafactory operators, quantum infra providers | expanded | 擴展 EuroHPC 至 AI gigafactories 與量子技術，新增 17% 資本支出共同出資要求 |
| EU | EuroHPC AI Initiative Corrigendum | AI startups, EuroHPC participants, Member States | clarified | 術語更正（factory→facility），無實質義務變更 |
| CSA | AI Governance Framework Adoption | AI Governance Officers, Cloud Architects, Security Engineers, Compliance Teams | new | 雲原生 AI 系統需採用結構化治理框架因應分散式架構挑戰 |
| CSA | Leveling Up Autonomy in Agentic AI | AI System Architects, Security Engineers, Enterprise Risk Officers, Infrastructure Engineers | clarified | 需定義並治理不同 AI 自主層級，含程式碼執行、基礎設施管理、財務交易 |
| CSA | From Security to Proof of AI Trust | Security Engineers, Enterprise Architects, Business Leaders, Audit Teams, AI System Owners | new | 自主/半自主 AI 系統需建立信任證明機制 |
| CSA | Agentic Trust Framework | Security Engineers, Enterprise Architects, Business Leaders, AI System Developers | new | 引入 AI 代理專用 Zero Trust 治理框架 |
| CSA | What AI Risks Are Hiding in Your Apps | Application Security Teams, AI Risk Officers, Security Operations, API Security Teams | clarified | 需識別與管理應用程式內嵌 AI 風險 |
| CSA | Non-Human Identity Governance | Identity Governance Admins, IAM Architects, Security Operations, Cloud Security Engineers | clarified | 傳統 IGA 系統不足以治理非人類身分 |
| CSA | Time-to-Trust Survey | CISO, IAM Architects, Security Engineers, Enterprise Architects | expanded | IAM 架構需擴展以容納 AI 代理 |
| CSA | AI Knowing When to Say I Don't Know | AI System Developers, Security Engineers, AI Governance Teams, Product Managers | clarified | AI 系統需內建不確定性校準機制 |
| CSA | First Question Security Should Ask | Security Teams, AI Project Leaders, Business Stakeholders, Risk Officers | clarified | 安全團隊需以「Why」問題引導 AI 專案 |
| CSA | Global Privacy Trends 2026 | DPO, Privacy Officers, Compliance Teams, Legal Counsel, Security Architects | expanded | 全球隱私合規進入新階段，執法趨嚴 |
| CSA | Top 10 Predictions for Agentic AI | AI Security Officers, Enterprise Architects, Security Researchers, Business Leaders | informational | 2026 標誌 Agentic AI 時代全面到來 |
| CSA | Great Divide: AI Splitting Cybersecurity | CISO, Security Team Leads, Security Strategy Planners, Enterprise IT Management | clarified | 2026 為 AI 資安應用分水嶺 |
| CSA | SaaS and AI Security in 2026 | Security Teams, SaaS Admins, AI Security Officers, Identity Governance Teams | clarified | AI 採用循 SaaS 進入模式，需新安全方法 |
| NIST | Lessons Learned: Tool Use in Agent Systems | AI developers, deployers, downstream users, researchers, supply chain participants | new | 需採用標準化分類法描述代理工具能力與限制 |
| NIST | AI Centers for Manufacturing & Critical Infra | AI developers, manufacturing orgs, critical infra operators, federal R&D centers | new | 新設 AI 經濟安全中心 |
| NIST | Managing Cybersecurity and Privacy Risks in AI Age | AI developers, deployers, cybersecurity/privacy professionals | expanded | 資安隱私專業人員需整合 AI RMF |
| ISO | AI Transparency Taxonomy | ISO 標準實施人員 | new | 發布新版 ISO AI 透明度分類標準 |
| SANS | Detecting OpenClaw | Security operations, System admins, AI security specialists, Network security engineers, Compliance officers | new | 新型 AI 代理框架 OpenClaw 需建立偵測監控機制 |
| SANS | Scanning for exposed Anthropic Models | Security analysts, AI infra admins, API security teams, Network security engineers | informational | 偵測針對 Anthropic API 端點掃描活動 |

---

## 義務與舉證要求

### 新增義務摘要

**歐盟（EU）**：
- EuroHPC Joint Undertaking 擴展至建立與營運 AI gigafactories
- 會員國需提供最高 17% 資本支出共同出資
- 建立 AI 處理器採購框架合約
- 授予合格基礎設施「EuroHPC AI and Compute Infrastructure Seal」
- AI 系統提供者與部署者需重新評估線上環境的合規義務（AI Act 勘誤）

**美國（NIST）**：
- AI 系統開發者與部署者需採用標準化分類法描述代理工具能力與限制
- 採用七種分類方法（功能性、存取模式、風險導向、可靠性、模態、監控、自主性）
- 整合 AI RMF 管理新風險，擴展傳統資安隱私職責
- 評估工具使用的風險層級（危害嚴重性、狀態性、可逆性）
- 建立監控機制與可觀察性層級

**產業指引（CSA）**：
- 雲原生 AI 系統需採用結構化治理框架
- 實施分階段治理框架導入方案
- 定義並文件化企業系統中的 AI 自主層級
- 建立與自主層級相符的治理機制
- 自主 AI 操作（程式碼執行、基礎設施變更、財務交易）風險評估
- 建立 AI 代理專用 Zero Trust 治理框架
- 識別與管理應用程式內嵌 AI 風險
- 擴展 IAM 架構以容納 AI 代理
- 建立 AI 信任證明機制
- AI 系統需具備內在不確定性感知

**國際標準（ISO）**：
- 採用 AI 系統透明度分類法進行透明度評估

**威脅情報（SANS）**：
- 建立 OpenClaw 等 AI 代理框架偵測與監控機制
- 保護本地部署的 AI 模型 API

### 舉證要求摘要

**歐盟（EU）**：
- 會員國 RRF 貢獻與存取時間分配紀錄
- AI gigafactory 營運合規文件
- 實體空間與線上空間之分類證明文件
- AI 系統部署環境說明文件

**美國（NIST）**：
- AI 代理工具能力與限制分類文件
- 供應鏈溝通、風險評估與事件報告紀錄
- 工具分類映射（依功能、存取模式或多維度交集）
- 風險評估報告，涵蓋危害、狀態性與可逆性
- 監控與日誌機制文件

**產業指引（CSA）**：
- AI 治理框架選擇與導入文件
- 分階段實施計畫與成熟度里程碑
- 分散式 AI 系統治理控制措施
- 治理成熟度評估紀錄
- AI 自主層級分類文件
- 與自主層級相符的治理框架
- 自主操作風險評估紀錄
- ATF 實施文件與稽核日誌
- AI 信任框架文件與驗證機制
- AI 不確定性校準方法論文件

---

## L5 — Evolution Signals

1. [系統推論] **AI 代理治理成為獨立領域** — 本期 CSA 連續發布 Agentic Trust Framework、Levels of Autonomy、Non-Human Identity Governance 等指引，顯示 AI 代理（Agentic AI）已從 AI 治理的子議題，演化為需要專門框架的獨立領域。傳統身分治理（IGA）與 Zero Trust 架構正在針對非人類身分與自主代理進行根本性調適。

2. [系統推論] **美歐在 AI 基礎設施投資呈現分歧策略** — 歐盟透過 EuroHPC 修正案建立「AI gigafactories」集中式投資框架（41.2 億歐元），強調技術主權與戰略自主；美國 NIST 則採分散式策略，新設製造業與關鍵基礎設施 AI 經濟安全中心，著重實務應用與人才培育。兩區域 AI 治理路徑呈現「集中式投資 vs. 分散式應用」的分歧。

3. [系統推論] **AI 風險管理從「合規導向」轉向「信任證明」** — CSA「From Security to Proof of AI Trust」提出從安全到信任證明的典範轉移，配合 ISO AI 透明度分類標準的發布，顯示全球 AI 治理正從「符合框架要求」轉向「可驗證的信任證明」。當 AI 系統以超越人類速度執行操作時，傳統安全協議已不足夠，新典範強調 AI 系統需「證明其可信」而非「被動保護」。

---

## 統計

| 指標 | 數值 |
|------|------|
| 總變動數 | 30 |
| 來源分布 | CSA: 13, NIST Frameworks: 6, EU: 4, NIST Insights: 4, SANS: 2, ISO: 1 |
| rule_type 分布 | guidance: 17, amendment: 4, new: 2, informational: 4, unknown: 3 |
| enforcement_signal 分布 | recommended: 17, informational: 4, mandatory: 3, unknown: 6 |
| REVIEW_NEEDED | 0 筆 |

---

## 資料來源

| Layer | Category | 筆數 | 時間範圍 |
|-------|----------|------|----------|
| csa_cloud_security | ai_security, identity, compliance, best_practices | 13 | 2026-01-06 ~ 2026-02-03 |
| nist_frameworks | ai_risk | 6 | 2025-08-05 ~ 2025-12-22 |
| eu_regulations | ai_governance, critical_infrastructure | 4 | 2026-01-13 ~ 2026-01-27 |
| nist_cybersecurity_insights | ai_risk, workforce, supply_chain | 4 | 2024-09-19 ~ 2025-09-30 |
| sans_isc | threat_analysis | 2 | 2026-02-02 ~ 2026-02-03 |
| iso_standards | other | 1 | 2025-11-11 ~ 2025-11-11 |

---

*報告產出時間：2026-02-13*
