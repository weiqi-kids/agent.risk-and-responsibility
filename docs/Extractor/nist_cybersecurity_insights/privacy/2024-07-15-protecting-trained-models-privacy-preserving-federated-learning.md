---
title: "Protecting Trained Models in Privacy-Preserving Federated Learning"
source_url: https://www.nist.gov/blogs/cybersecurity-insights/protecting-trained-models-privacy-preserving-federated-learning
date: 2024-07-15
category: privacy
confidence: 中
---

## L1 — Rule Signal
- **rule_type**: guidance
- **issuing_body**: NIST
- **document_id**: N/A
- **status**: final

## L2 — Responsibility Structure
- **affected_roles**: AI/ML developers, privacy engineers, organizations using federated learning
- **shift_type**: expanded
- **shift_summary**: 在討論完輸入隱私技術後，本文擴展至訓練模型的保護，需涵蓋水平與垂直資料分割情境以建構完整的 PPFL 系統

## L3 — Risk Domains
- 模型保護
- 隱私保護技術
- 聯邦學習安全

## L4 — Obligation & Evidence
- **new_obligations**:
  - 完整的 PPFL 系統需同時保護輸入隱私與訓練模型
- **evidence_requirements**:
  - 無明確舉證要求
- **enforcement_signal**: recommended

## Notes
本文為 NIST 與 UK RTA（前 Centre for Data Ethics and Innovation）合作的隱私保護聯邦學習系列，涵蓋水平與垂直分割資料情境的模型保護技術。
