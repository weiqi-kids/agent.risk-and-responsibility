---
title: "Protecting Model Updates in Privacy-Preserving Federated Learning"
source_url: https://www.nist.gov/blogs/cybersecurity-insights/protecting-model-updates-privacy-preserving-federated-learning
date: 2024-03-21
category: privacy
confidence: 中
---

## L1 — Rule Signal
- **rule_type**: guidance
- **issuing_body**: NIST (in collaboration with UK Responsible Technology Adoption Unit)
- **document_id**: N/A (blog series post)
- **status**: final

## L2 — Responsibility Structure
- **affected_roles**: privacy-preserving federated learning practitioners, horizontally partitioned data system developers, input privacy implementers
- **shift_type**: clarified
- **shift_summary**: 說明在資料水平分割（horizontally partitioned）情境下，如何提供 input privacy 保護，涵蓋 PPFL 模型訓練與聚合流程

## L3 — Risk Domains
- Privacy-preserving federated learning
- Horizontally partitioned data
- Input privacy techniques
- Model aggregation security

## L4 — Obligation & Evidence
- **new_obligations**: N/A (technical guidance)
- **evidence_requirements**: N/A
- **enforcement_signal**: informational

## Notes
本文為 NIST-UK RTA 合作系列之一，前篇描述 models/training/aggregation 與 horizontal/vertical partitioning 概念，本篇探討 horizontally-partitioned federated learning 的 input privacy 技術。系列文章發布於 NIST Privacy Engineering Collaboration Space 與 RTA blog。Description 足夠判斷文章主題，未使用 WebFetch。
