---
title: "Logic-Layer Prompt Control Injection (LPCI): A Novel Security Vulnerability Class in Agentic Systems"
source_url: https://cloudsecurityalliance.org/articles/logic-layer-prompt-control-injection-lpci-a-novel-security-vulnerability-class-in-agentic-systems
date: 2026-01-30
category: ai_security
confidence: 高
---

## L1 — Rule Signal
- **rule_type**: guidance
- **issuing_body**: Cloud Security Alliance (CSA)
- **document_id**: N/A
- **status**: final

## L2 — Responsibility Structure
- **affected_roles**: AI 安全研究員、AI 系統架構師、安全工程師、AI 開發者
- **shift_type**: new
- **shift_summary**: 識別並定義新型安全漏洞類別 LPCI，要求 agentic AI 系統開發者納入此漏洞的防護措施

## L3 — Risk Domains
- AI 系統安全
- Prompt injection 攻擊防護
- 自動化代理邏輯層安全

## L4 — Obligation & Evidence
- **new_obligations**:
  - 識別 agentic AI 系統中的 LPCI 風險點
  - 在系統設計階段考慮邏輯層 prompt 控制注入防護
  - 對自主代理系統進行 LPCI 漏洞評估
- **evidence_requirements**:
  - LPCI 風險評估報告
  - 邏輯層防護設計文件
  - 漏洞測試結果
- **enforcement_signal**: recommended

## Notes
由 CSA Fellow Ken Huang 與 AI 安全專家共同撰寫，聚焦於 agentic systems 中新型安全漏洞的定義。Description 提供足夠背景（約 440 字元）。
